# 场景 1: 只启用 CLIP 服务
# 用途: 图片分类、文本嵌入、场景分类
# 内存占用: 低

metadata:
    version: "1.0"
    region: "cn" # "other" 使用 HuggingFace, "cn" 使用 ModelScope
    cache_dir: "~/.lumen"

# 可选: Python 包依赖（如果需要自动安装）
dependencies:
    - "lumen-clip @ git+https://github.com/EdwinZhanCN/Lumen.git@main#subdirectory=lumen-clip"

services:
    clip:
        enabled: true
        package: "lumen-clip"
        import:
            registry_class: "image_classification.clip_service.CLIPService"
            add_to_server: "ml_service_pb2_grpc.add_InferenceServicer_to_server"
        models:
            default:
                model: "MobileCLIP2-S2"
                runtime: "torch"
                dataset: "ImageNet_1k"
        default_model: "default"
        env:
            # 可选的环境变量配置
            BATCH_SIZE: "8"
        server:
            port: 50051
            mdns:
                enabled: true
                name: "CLIP-Service"
                type: "_lumen-clip._tcp.local."
