# Lumen Services Configuration - Single Service Mode
# yaml-language-server: $schema=https://doc.lumilio.org/schema/config-schema.yaml

metadata:
    version: "1.0.0"
    region: "cn" # "cn" for ModelScope, "other" for HuggingFace
    cache_dir: "~/Lumen-Resources" # ~/.lumen by default

deployment:
    mode: "single"
    service: "clip"

server:
    port: 50051
    host: "0.0.0.0"
    mdns:
        enabled: true
        service_name: "lumen-clip"

services:
    # CLIP Service
    clip:
        enabled: true
        package: "lumen_clip"
        import:
            registry_class: "lumen_clip.service_registry.CLIPService"
            add_to_server: "lumen_clip.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"
        backend_settings:
            device: "mps"
            onnx_providers:
                - "CoreMLExecutionProvider"
            batch_size: 8
        models:
            bioclip:
                model: "bioclip-2"
                runtime: torch      # torch | onnx | rknn
                dataset: TreeOfLife-10M # TreeOfLife-200M
            general:
              model: "MobileCLIP2-S2" # CN-CLIP_ViT-L-14 | CN-CLIP_ViT-B-16 | MobileCLIP2-S2
              runtime: torch       # torch | onnx | rknn
              dataset: ImageNet_1k