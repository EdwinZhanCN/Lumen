# Lumen Services Configuration - Single Service Mode
# yaml-language-server: $schema=https://doc.lumilio.org/schema/config-schema.yaml

metadata:
    version: "1.0.0"
    region: "cn" # "cn" for ModelScope, "other" for HuggingFace
    cache_dir: "/Volumes/CodeBase/Lumen-Resources" # ~/.lumen by default

deployment:
    mode: "hub"
    services:
        - "clip"
        - "ocr"

server:
    port: 50051
    host: "0.0.0.0"
    mdns:
        enabled: true
        service_name: "lumen-clip"

services:
    # CLIP Service
    clip:
        enabled: true
        package: "lumen_clip"
        import_info:
            registry_class: "lumen_clip.general_clip.GeneralCLIPService"
            add_to_server: "lumen_clip.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"
        backend_settings:
            device: null
        models:
            general:
                model: "CN-CLIP_ViT-B-16" # CN-CLIP_ViT-L-14 | CN-CLIP_ViT-B-16 | MobileCLIP2-S2 | MobileCLIP2-S4
                runtime: onnx
                dataset: ImageNet_1k
                precision: fp16
    ocr:
        enabled: true
        package: lumen_ocr
        import_info:
            registry_class: "lumen_ocr.general_ocr.GeneralOcrService"
            add_to_server: "lumen_ocr.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"
        backend_settings:
            device: null # auto-detect
            onnx_providers:
                - CPUExecutionProvider
        models:
            general:
                model: "PP-OCRv5" # PP-OCRv5
                runtime: onnx
                precision: fp32
