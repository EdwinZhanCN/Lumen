# Lumen Services Configuration - Single Service Mode
# yaml-language-server: $schema=../config-schema.yaml

metadata:
    version: "1.0.0"
    region: "other" # "cn" for ModelScope, "other" for HuggingFace
    cache_dir: "~/.lumen/models"

deployment:
    mode: "single"
    service: "clip"

server:
    port: 50051
    host: "0.0.0.0"
    mdns:
        enabled: true
        service_name: "lumen-clip"

services:
    # CLIP Service
    clip:
        enabled: true
        package: "lumen_clip"
        import:
            registry_class: "lumen_clip.service_registry.ClipService"
            add_to_server: "lumen_clip.proto.ml_service_pb2_grpc.add_InferenceServicer_to_server"

        models:
            # Default general-purpose CLIP model
            default:
                model: "ViT-B-32"
                runtime: "torch"
                dataset: "ImageNet_1k"

            # Chinese CLIP model
            cn_clip:
                model: "CN-CLIP-ViT-B-16"
                runtime: "onnx"
                dataset: "ImageNet_1k"

            # Mobile-optimized model
            mobile:
                model: "MobileCLIP2-S2"
                runtime: "onnx"

            # RKNN-accelerated model for RK3588
            rk3588:
                model: "MobileCLIP2-S2"
                runtime: "rknn"
                rknn_device: "rk3588"
                dataset: "ImageNet_1k"
